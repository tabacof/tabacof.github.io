<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">

<head>
<link rel="icon" href="img/pt.jpg">
<meta http-equiv="content-type" content="text/html; charset=UTF-8"/>
<meta name="description" content="description"/>
<meta name="keywords" content="keywords"/> 
<meta name="author" content="author"/> 
<link rel="stylesheet" type="text/css" href="default.css" media="screen"/>
<title>Pedro Tabacof</title>
</head>

<body>

<div class="outer-container">

<div class="inner-container">

	<div class="header">
		
		<div class="title">

			<span class="sitename"><a href="index.html">Pedro Tabacof</a></span>
		</div>
		
	</div>

	<div class="path">
			
			<a href="index.html">Home</a> &#8250; <a href="index.html">Research Interests</a>

	</div>

	<div class="main">		
		
		<div class="content">

			<h2>Research Interests</h2>
			<br>
			<h3>Variational autoencoders </h3>
			<p> I am interested in understanding the latent representation of variational autoencoders. Is latent variable arithmetic as effective as word2vec analogies? I am exploring this question through an artificial dataset that allows me to correctly identify the expected result of the latent arithmetic operations. Currently I am using standard and convolutional variational autoencoders, but I intend to use more advanced architectures in the future, such as the combination of generative adversarial networks and variational autoencoders. </p>

			<h3>Adversarial images</h3>
			<p> How common are adversarial images in the input space of deep neural networks? I have tried to answer this question through empirical evaluations of how deep convolutional nets react to input noise under different statistical considerations. This work has led to an IEEE conference publication. See the <a href="publications.html">publications</a> page for more information. </p>

			<h3>Bayesian neural networks</h3>
			<p> In theory, Bayesian neural networks won't overfit, get stuck in local minima and they can provide weight and prediction uncertainties. In practice, the inference is intractable, so some approximation must be used, and by doing so we may lose one or more of the said advantages. However, modern neural networks rarely overfit and they get stuck in saddle points instead of local minima (which are pretty much equivalent). The only things a modern neural network lacks is uncertainty. With this in mind, I am exploring the practical advantages a Bayesian neural net may have over traditional nets on problems where some test classes are not part of the training set. </p>

			<h3> General interests </h3>
			<i>Software experience in parenthesis.</i>
			<ul>
			<li> Machine learning 
			<ul>
			<li> Deep learning (Torch7, Theano, Lasagne, Chainer) </li> 
			<li> Variational autoencoders (Parmesan) </li>
			<li> SVM, random forests, logistic regression (Scikit-learn) </li>
			</ul> </li>
			<li> Statistics
			<ul> 
			<li> Bayesian inference (PyMC, Stan) </li>
			<li> Gaussian processes (GPy) </li>
			<li> Time-series (R forecast) </li> 
			</ul> </li>
			<li> Optimization
			<ul> 
			<li> Convex (CVX) </li>
			<li> Nonlinear (Ipopt, MPFIT, L-BFGS) </li>
			<li> Genetic algorithms and evolutionary strategies </li>
			</ul> </li>
			<li> Control
			<ul> 
			<li> Fuzzy control (Leaf) </li>
			<li> Optimal control (Matlab) </li>
			<li> System identification (SysId toolbox) </li>
			<li> Nonlinear model-based control (CasADi) </li>
			</ul> </li>
			</ul>
		</div>

		<div class="navigation">

			<h2>Navigation</h2>
			<ul>
				<li><a href="research.html">Research Interests</a></li>
				<li><a href="publications.html">Publications</a></li>
				<li><a href="professional.html">Professional Experience</a></li>
				<li><a href="teaching.html">Teaching</a></li>
				<li><a href="social.html">Social Media</a></li>
				<li><a href="resume.pdf">Resume</a></li>
			</ul>

		</div>

		<div class="clearer">&nbsp;</div>

	</div>

	<div class="footer">

		<span class="left">
			&copy; 2016 <a href="index.html">Pedro Tabacof</a>. Valid <a href="http://jigsaw.w3.org/css-validator/check/referer">CSS</a> &amp; <a href="http://validator.w3.org/check?uri=referer">XHTML</a>
		</span>

		<span class="right"><a href="http://templates.arcsin.se/">Website template</a> by <a href="http://arcsin.se/">Arcsin</a></span>

		<div class="clearer"></div>

	</div>

</div>

</div>

</body>

</html>
